# 2025.07.28.
日小结

<a id="top"></a>
根据[ego模型时间接口](https://gitee.com/hyg/blog/blob/master/timeflow.md)，今天绑定模版2(2c)。

<a id="index"></a>
- 14:00~16:59	ego: [整理task及其相互关系](#20250728140000)

---
season stat:

| task | alloc | sold | hold | todo |
| :---: | ---: | ---: | ---: | ---: |
| total | 13530 | 5856 | 7674 | 8640 |
| PSMD | 4000 | 1100 | 2900 | 1230 |
| ego | 2530 | 720 | 1810 | 1335 |
| infra | 2000 | 425 | 1575 | 405 |
| xuemen | 1000 | 90 | 910 | 600 |
| raw | 1000 | 70 | 930 | 390 |
| learn | 2000 | 3081 | -1081 | 3000 |
| js | 1000 | 370 | 630 | 1680 |

---
waiting list:


- 30分钟时间片：
  - js的第1号事项：a2a-js
  - js的第3号事项：graphviz
  - learn的第3号事项：Agent Protocol https://agentprotocol.ai/
  - learn的第5号事项：claude code + kimi K2 @ bailian

- 60分钟时间片：
  - PSMD的第1号事项：PSMD agent AI的内部角色和功能
  - infra的第1号事项：结合AI进展重新规划架构
  - raw的第1号事项：设计新的季度时间表
  - xuemen的第1号事项：根据最新政策文件，考虑AER、AVR文件升级。

- 90分钟时间片：
  - ego的第1号事项：整理task及其相互关系
  - learn的第1号事项：业务规则引擎
  - PSMD的第2号事项：筹备会议 by role+prompt
  - ego的第3号事项：基于真实数据标志财务报表

- 195分钟时间片：
  - xuemen的第2号事项：kernel模型升级
  - PSMD的第3号事项：machines model
  - infra的第4号事项：Rete/Phreak算法的自主实现
  - xuemen的第4号事项：重新设计S2状态下的学门基本管理制度

---
<a href="mailto:huangyg@mars22.com?subject=关于2025.07.28.[整理task及其相互关系]任务&body=日期: 2025.07.28.%0D%0A序号: 6%0D%0A手稿:../../draft/2025/20250728.01.md%0D%0A---请勿修改邮件主题及以上内容 从下一行开始写您的想法---%0D%0A">[email]</a> | [top](#top) | [index](#index)
<a id="20250728140000"></a>
## 14:00 ~ 16:59
## ego: [整理task及其相互关系]

- 使用这个提示语，借助AI提取概念、关系，准备定义层级：
```
1. 你怎么看xxxx（为什么你认为xxxx）？
2. 请对上面第1个问题的回答进行NER（命名实体识别）和RE（关系抽取），以json格式输出结果。
3. 请对上面第2个问题抽取的三元组逐个分析：在第1个问题相关的范围内，哪些三元组关系可以假设是稳定的，哪些是可能变化的、存在其它选择的？请补充列出可能变化的三元组以及并列关系，分析它们之间的范围或概率，对第1个问题的影响。
```
- mistral很敷衍，受不公开的前提约束，因此视野非常窄。
- kimi回答得很尽责，但是绕过第1个问题的回答，从上一个问答总选了几个句子分别进行NER、RE，第3问题徒有其表，内容出现幻觉。可能算力不足。
- deepseek回答很尽责，NER,RE的范围很窄，也是绕过第一个问题。第3问也有幻觉。
- 豆包回答尽责，NER、RE对题而且很细致。第3问内容远远少于2的回答，不过选取上还是有重点。
- gemini pro：第1问比较认真，第2问从第1问回答中选取了少量内容，不过还算有重点。第3问非常尽责，对第2问结果全覆盖而且分析有理有据。前面问自习资料时只从历史手稿中选取，要求外部资料则提供了许多虚假url，而且把完整url转给google搜索，视图蒙混过去。
- chatgpt: 第1问比较认真，第2问对第1问的抽取覆盖率很高，第3问尽责但是不太准确全面、有点敷衍，最后总结视野比较完整、连贯。前面问答也非常尽责，从我工作角度给出建议，提供的资料都是真实的。
- grok: 第1问对题，简练、能覆盖重点但不深入。第2问能覆盖第1问的内容。第3问忘记了前面问题内容（我的工作内容），能覆盖第2问内容，分析比较粗浅、不算准确。前面问题就很敷衍，追问后给出一些虚假链接。对工作瓶颈没有深入分析。
- GLM-4.5: 第1问尽责，第2问覆盖第1问，提取比较准确全面，第3问认真、稳定分析比较准确但是对并行关系的分析不准确。

- 不能在同一个对话中进行，把1、2、3拆开分别问不同的ai，或者不加入history中，截取部分继续逐个问。
	- 1. kimi、deepseek、豆包、gemini pro、chatgpt、GLM-4.5都可以。
	- 2. 豆包、chatgpt、grok、GLM-4.5。
	- 3. gemini pro，GLM-4.5，豆包可以试试、也许是算力限制没展开回答，mistral可以试试、对已有的三元组挑刺它可能擅长。

- 准备用代码自动询问，生成新task以及层级关系。根据收费情况选择AI按以下分工提问：
	- 第1问，原始问题常规提问。
	- 第2问，除了NER、RE以外，还要按原始问题的重要程度分级。
	- 第3问，原始问题和单个关系分别提问。
	- 第4步，按照关系的重要程度、稳定性和变化概率分级，产生下一层级的问题，重复第1问。
		- 维护好问题-关系-变化（aka新问题）的关系元数据
		- 要求画出mermaid语法的关系图
- 下一个时间片用代码试试。
